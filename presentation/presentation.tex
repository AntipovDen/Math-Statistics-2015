\documentclass[hyperref=unicode,graphics=pdflatex,13pt]{beamer}

\mode<presentation>
{
  \usetheme{default}
%  \usecolortheme{crane}
  \setbeamercovered{invisible}
  \setbeamertemplate{footline}{\hfill\insertframenumber/\inserttotalframenumber}
  \setbeamersize{text margin left=0.4cm,sidebar width left=0cm}
}

\graphicspath{{pic/}}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[english, russian]{babel}
\usepackage{times}
\usepackage{color, colortbl}
\definecolor{res}{RGB}{255, 215, 0}
\definecolor{olivegreen}{RGB}{38, 141, 38}
\usepackage{xspace}
\usepackage{tabularx}

\beamertemplatenavigationsymbolsempty
%\setbeamerfont{page number in head/foot}{size=\HUGE}


\title[Dishonest Casino Problem\ldots]{Solving Dishonest Casino Problem \\ With Evolutionary Algorithms}

\author[\mbox{V. Mironovich, D. Antipov, V. Volochay}]
{V. Mironovich \and D. Antipov \and V. Volochay}
\institute[Университет ИТМО]{{\includegraphics[height=0.2\textwidth]{pic/itmo-dots-en-small.pdf}}\\~\\~Saint-Petersburg, Russia}
\date[June 4]{June 4, 2015}

% NOTE: I HATE USELESS TOCS
%\AtBeginSection[] {
%  \begin{frame}<beamer>{}
%    \tableofcontents[currentsection]
%  \end{frame}
%}

\begin{document}

\begin{frame}[noframenumbering,plain]
  \titlepage
\end{frame}

% NOTE
%\begin{frame}[noframenumbering,plain]
%  \tableofcontents
%\end{frame}

\section{Introduction}

% NOTE
%subsection too much
%\subsection{Dishonest Casino Problem}
\begin{frame}{Original Dishonest Casino Problem}
\begin{itemize}
   \item Casino uses two dices
   \item One is fair, the other one is weighted to produce more sixes
   \item Casino switches the dices at unknown times
   \item We know probabilities for Markov process and dice distributions
   \item Detect switch times
\end{itemize}

\centering{Solved with DynProg or previosly reported algorithms.}
\end{frame} 

\begin{frame}{Proposed statement of DCP}
 \begin{itemize}
  \item Still the same two dices
  \item We know nothing about probabilities and distributions
  \item The underlying process is still the same
  \item Detect switch times
  \end{itemize}

\end{frame}

% NOTE: Somethign something
%\begin{frame}{Group work process}
% \begin{itemize}
%  \item Everyone worked on his own solution
%  \item Exchanging ideas and suggestions
% \end{itemize}
%\end{frame}


\section{Solution} %kay m8 
\begin{frame}{Solution}
  \begin{itemize}
   \item Let's try something with evolutionary algorithm
   \item Why? Because we can...probably
   \item Logic from evolution in nature
   \item Represent individual => Mutate and Reproduce => Optimize fitness function => ??? => Profit
  \end{itemize}

\end{frame}

\begin{frame}{Evolutionary algorithm}
 \begin{itemize}
  \item Generate a binary vector $S$ and assume:
   \begin{itemize}
   \item $S_t = 0$, if $X_t$ was given by first generator
   \item $S_t = 1$, if $X_t$ was given by second generator
   \end{itemize}
  \item Mutation: flipping random bit
  \item Crossover: single-point exchange of tails
 \end{itemize}
\end{frame}

\begin{frame}{Choosing fitness}
\begin{itemize}
   \item Minimize the average deviation of $p(S_i=s | X_i = x)$ calculated by the Bayes theorem from this probabilities calculated by assumption vector
   \item Maximize the Bhattacharyya distance beetween the sourse distributions:
   $$D_B(p, q) = -\ln{\sum_{\omega \in \Omega} \sqrt{p(\omega)q(\omega)}}$$
   \item %TODO: Tut Vika rasskazhet pro Kolmagorova
\end{itemize}

\end{frame}

\section{Failures 1}
\begin{frame}{Failures: Conditional probability}
 \begin{itemize}
  %TODO: Denis, try to describe why using conditional probability doesn't work in this slide, maybe put examples, like in next mine
  \item Minimizing the deviation of conditional probability leads to getting ...
 \end{itemize}

\end{frame}

\begin{frame}{Failures: Bhattacharyya distance}
\begin{itemize}
 \item Bhattacharyya distance is prone to overfitting. Falls into making two generators ``absolutely distinct'' and the distance equal to $\infty$
 \item Try to force the equality of generators' domains by making $p(x) = max(1/len(S), p(x_i))$
 \item Works better but still overfits
\end{itemize}
\end{frame}

\begin{frame}{Overfitting}
 %TODO overfitting example
  \begin{itemize}
   \item Length = 100, (0.5, 0.5) probabilities
   \begin{itemize}
   \item distance of original 2.01, distance of found 3.24
   \item Guessed: 24 out of 44, 54.5\%
   \item Wrong: 25 out of 49, 51\%
   \end{itemize}
  \item Length = 100, (0.9, 0.35) probabilities
  \begin{itemize}
   \item distance of original 1.60, distance of found 3.22
   \item Guessed: 12 out of 25, 48.0\%
   \item Wrong: 39 out of 51, 76\%
  \end{itemize}


  \end{itemize}
\end{frame}

\begin{frame}{Overfitting}
 \begin{itemize}
  \item Assume we know Bhattacharyya distance for our sequence
  \item Optimize to it ($ abs(bchd(S)-actual) $
 %TODO example here
  \item Length = 100, (0.5, 0.5) probabilities
  \begin{itemize}
   \item Guessed: 27 out of 52, 51.92307692307692\%
   \item Wrong: 34 out of 61, 55\%
  \end{itemize}
  \item Length = 100, (0.9, 0.35) probabilities
  \begin{itemize}
   \item distance of original 1.77, distance of found 1.82
   \item Guessed: 6 out of 25, 24.0\%
   \item Wrong: 38 out of 44, 86\%
  \end{itemize}
  \item Questionable
  \end{itemize}
\end{frame}

%TODO Assuming that kolmogorov is shitty too, insert something here


\section{Current ideas in work}

%TODO hey, describe your shit here
\subsection{Sliding windows}
\begin{frame}{One sliding window}
\begin{itemize}
   \item Choose the length of the window equal to the expected length of non-switching subsequence of $S$
   \item We can calculate the expectation for every position of window of the in-window sequence
   \item It gives us nothing even after smoothing the expectations:
   %TODO: some pictures here 
\end{itemize}
\end{frame}

\begin{frame}{One sliding window}
\begin{itemize}
   \item Basing on calculated expectations we can try to assume that expectations of sources are the max and min expectation
   \item With this assumption we can try to find probabilities of each source on every step
   \item %TODO check the probability again or say that it is useless
\end{itemize}
\end{frame}

\begin{frame}{Two Sliding Windows}
\begin{itemize}
   \item Two sliding windows without interval between them
   \item Check the difference between them:
   \begin{itemize}
      \item difference of expectations
      \item Bhattacharyya distance
   \end{itemize}
   \item Nothing of it correlates with the real $S$
\end{itemize}

\end{frame}

\subsection{Produce minimum number of values}
%TODO frames:
%	- assumption of minimum number of generations
%	- still using Bhattacharyya
%	- it ``kinda'' works slide
% 	- leniency allowed, results

\subsection{Whatever Vika is doing}
%TODO may swap places in presentation

\section{Conclusion} %\sextion lololo

\begin{frame}{Conclusion}
 \begin{itemize}
  \item such conclusion
  \item much results
  \item very schientificz
  \item wow
 \end{itemize}

\end{frame}


\end{document}

